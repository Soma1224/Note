# 剑指Java面试-Offer直通车 开放

## 网络知识部分

### OSI开放系统互联参考模型

![7层网络](.\picture\7层网络.jpg)

### TCP的三次握手

如何看TCP的三次握手？

利用抓包工具和正则表达式筛选出三次握手的过程



![1550732621657](.\picture\22.png)

![1550731954270](.\picture\334.png)



#### 疑问一，上图传递过程中出现的几个字符（SYN,ACK,FIN,seq,ack）各代表什么意思

SYN，ACK，FIN存放在TCP的标志位，一共有6个字符，这里就介绍这三个：

**SYN**：代表请求创建连接，所以在三次握手中前两次要SYN=1，表示这两次用于建立连接，至于第三次什么用，在疑问三里解答。

**FIN**：表示请求关闭连接，在四次分手时，我们发现FIN发了两遍。这是因为TCP的连接是双向的，所以一次FIN只能关闭一个方向。

**ACK**：代表确认接受，从上面可以发现，不管是三次握手还是四次分手，在回应的时候都会加上ACK=1，表示消息接收到了，并且在建立连接以后的发送数据时，都需加上ACK=1,来表示数据接收成功。

**seq**:序列号，什么意思呢？当发送一个数据时，数据是被拆成多个数据包来发送，序列号就是对每个数据包进行编号，这样接受方才能对数据包进行再次拼接。

初始序列号是随机生成的，这样不一样的数据拆包解包就不会连接错了。（例如：两个数据都被拆成1，2，3和一个数据是1，2，3一个是101，102，103，很明显后者不会连接错误）

**ack**:这个代表下一个数据包的编号，这也就是为什么第二请求时，ack是seq+1，

(这里要吐槽一下，当初不懂的时候查资料，发现好多地方把ACK和ack都搞混了，害的我被坑了好久...)

如果你仔细看了上面对每个字符的解释，那么相信我画的三次握手和四次分手的图你也就明白了。

再复习一遍　　　　

在创建连接时，

1.客户端首先要SYN=1,表示要创建连接，

2.服务端接收到后，要告诉客户端：我接受到了！所以加个ACK=1，就变成了ACK=1,SYN=1

3.理论上这时就创建连接成功了，但是要防止一个意外（见疑问三），所以客户端要再发一个消息给服务端确认一下，这时只需要ACK=1就行了。

三次握手完成！

在四次分手时，

1.首先客户端请求关闭客户端到服务端方向的连接，这时客户端就要发送一个FIN=1，表示要关闭一个方向的连接（见上面四次分手的图）

2.服务端接收到后是需要确认一下的，所以返回了一个ACK=1

3.这时只关闭了一个方向，另一个方向也需要关闭，所以服务端也向客户端发了一个FIN=1 ACK=1

4.客户端接收到后发送ACK=1，表示接受成功

四次分手完成！

我为什么没有在上面的过程中，加入seq和ack呢？就如我对这两个关键字的解释的一样，这两个是数据拆分和组装必备元素，所以所有的请求都需要这两个元素，只要明白了作用，就可以自己举一反三。

关于握手和分手，主要还是SYN,FIN,ACK的变化，这才是重点！

#### 疑问二，每次发送请求时为什么ack要+1

关于seq和ack关键字的解释中已经说明了。

#### 疑问三，为什么需要三次握手（原因有二）

- **为了初始化Sequence Number的初始值**

通讯双方必须初始化Sequence Number，也就是上图中的x和y，在第二次握手服务器发送了Sequence Number给客户端后，客户端需要回送报文给服务器说收到了这条Sequence Number

- **初次握手的隐患--SYN超时的问题**

下面解释明明两次就可以建立连接的为什么还要加第三次的确认。

如果发送两次就可以建立连接话，那么只要客户端发送一个连接请求，服务端接收到并发送了确认，就会建立一个连接。

可能出现的问题：如果一个连接请求在网络中跑的慢，超时了，这时客户端会重新发送请求，但是这个跑的慢的请求最后还是跑到了，然后服务端就接收了两个连接请求，然后全部回应就会创建两个连接，浪费资源！

如果加了第三次客户端确认，客户端在接受到一个服务端连接确认请求后，后面再接收到的连接确认请求就可以抛弃不管了。

**SYN攻击：**

在三次握手过程中，Server发送SYN-ACK之后，收到Client的ACK之前的TCP连接称为半连接（half-open connect），此时Server处于SYN_RCVD状态，当收到ACK后，Server转入ESTABLISHED状态。SYN攻击就是Client在短时间内伪造大量不存在的IP地址，并向Server不断地发送SYN包，Server回复确认包，并等待Client的确认，由于源地址是不存在的，因此，Server需要不断重发直至超时，这些伪造的SYN包将产时间占用未连接队列，导致正常的SYN请求因为队列满而被丢弃，从而引起网络堵塞甚至系统瘫痪。SYN攻击时一种典型的DDOS攻击，检测SYN攻击的方式非常简单，即当Server上有大量半连接状态且源IP地址是随机的，则可以断定遭到SYN攻击了

#### 疑问四，为什么需要四次分手

TCP是全双工的，发送方和接收方都需要FIN报文和ACK报文，所以需要在两个方向分别关闭，每个方向的关闭又需要请求和确认，所以一共就4次。



### TCP的四次挥手

![1550738257895](.\picture\554.png)





### UDP

![1550739927125](.\picture\664.png)



### TCP的滑动窗口

先明确两个概念RTT和RTO

![1550751035935](.\picture\774.png)

TCP是把数据分成段去发送，出于效率，我们不可能一段一段去发送

**TCP使用滑动窗口做流量控制和乱序重排，滑动窗口有两个特性：**

- 保证TCP的可靠性
- 保证TCP的流控制性

#### 窗口的概念

##### 发送方

发送方的发送缓存内的数据都可以被分为4类: 
1. 已发送，已收到ACK 
2. 已发送，未收到ACK 
3. 未发送，但允许发送 
4. 未发送，但不允许发送

![1550751784423](.\picture\887.png)

**2和3作为发送方的滑动窗口**

##### 接收方

![1550752035430](.\picture\1124.png)

1.已接收，已发送回值的状态

2.未接收，准备接收的状态

3.未接收，不能接收的状态（因为已经达到窗口的域值）

**其中2作为接收方的滑动窗口**

##### 滑动窗口的总结：

==TCP最基本的**传输可靠性**来源于**确认重传机制**，**发送窗口**只有在接收到接收端对于本段发送窗口字节的ACK确认才会移动发送窗口的左边界，**接收窗口**只有当前面所有的段都已经确认的情况下才会移动左边界，当在前面的字节未接收然而却收到后面的字节的时候，窗口是不会移动的==



### HTTP

- HTTP超文本传输协议是属于应用层的协议，是基于==请求==与==响应==模式的==无状态==的==应用层==协议，基于==TCP==的连接方式

**特点**：

- 支持客户/服务器模式
- 简单快速（客户端只需向服务器端发送请求方法（get和post）和url路径）
- 灵活（允许传输任意类型的对象）
- 无连接（限制每次连接只处理一个请求，服务器处理完客户的请求并收到客户的应答之后就断开连接，采用这种方式可以节省时间，从http1.1起默认使用了长连接，所谓的长连接指的是http下层tcp的长连接，也就是在每个http请求中，是无法知道http是否处于长连接的状态的，**始终要认为http在请求结束后连接就要关闭**，至于下层tcp是否在http结束请求后关闭连接都不会影响http上面这个特性）
- 无状态（http对于事务处理没有记忆能力，缺少状态必须被重传）



http版本有1.0、1.1和2.0，目前使用最广泛的是1.1，相较于1.0引入了Pipelining这项长连接技术



总结：

- 客户端向服务器发送一个请求报文，包含：请求方法，url，协议版本，请求头部，请求数据
- 服务器以一个状态行进行响应，包含：协议版本，成功或者错误代码，服务器信息，响应头部，响应数据



![1550805760800](.\picture\1125.png)



第四步如果连接模式是close（http1.0），则服务器主动关闭TCP连接，客户端被动关闭TCP连接；若连接模式是keep-alive（http1.1），该http连接保持一段时间，在这段时间内继续接收请求



##### 键入url，按下回车的流程？

- 首先浏览器会根据url逐层查询DNS服务器缓存，解析url中的域名所对应的IP地址，DNS缓存从近到远依次是：浏览器缓存，系统缓存，路由器缓存，IPS服务器缓存，域名服务器缓存，顶级域名服务器缓存，从哪个缓存查找到对应的IP则直接返回，不再查找
- 找到IP后，根据IP地址和对应端口（8080）进行TCP的三次握手连接
- 浏览器发送HTTP请求
- 服务器处理请求并返回HTTP报文
- 浏览器解析渲染页面
- 连接结束

![1550814775552](.\picture\1126.png)



##### 谈谈http的状态码？

![1550815727317](.\picture\1127.png)



![1550816040910](.\picture\1128.png)



##### get请求和post请求的区别？

从三个层面来进行回答：

- http报文层面：get将请求信息放在url（请求信息与url之间以问号隔开，请求信息的格式为键值对，由于放在url中，所以是有长度限制的，例如传输数据），post将请求信息放在报文体中（想获得请求信息必须解析报文，由于是放在报文体中，所以对数据长度是没有限制的，例如登录请求）
- 数据库层面：get请求符合==幂等性==（对数据库的一次操作和多次操作所取得的数据都是一致的）和==安全性==的（没有改变数据库中的数据），post请求不符合（get请求是查询数据库，post请求是提交数据到数据库的）
- 其他层面：get可以被缓存和存储，而post不行（浏览器可以缓存和存储get请求的url作为书签）

由于缓存是get请求被广泛应用的根本，原因是：由第二部分get请求是幂等的和安全的，一天产生的请求量太多了，web服务器根本处理不过来，所以绝大部分的get请求都被CDN（CDN的全称是Content Delivery Network，即[内容分发网络]缓存了，而post请求是需要被web服务器处理的。



##### cookie和session的区别？

![1550819669416](.\picture\1129.png)

![1550819686144](.\picture\1130.png)

![1550819804172](.\picture\1131.png)

![1550819947657](.\picture\1132.png)

![1550820043821](.\picture\1133.png)

##### HTTP和HTTPS的区别？

![1550820585549](.\picture\1134.png)



![1550820954669](.\picture\1135.png)

==第四条就是说https是有状态的，http是无状态的==

![1550821103854](.\picture\1136.png)



### Socket

提前知识：

- 在本地进程通讯中，可以用processID来唯一地标识一个进程，但是processID只在本地唯一，网络中地processID冲突还是有的
- 用IP地址+协议+端口号来唯一表示网络中的一个进程

![1551161361876](.\picture\1137.png)



![1551161387717](.\picture\1138.png)

此处需要注意的是：服务器执行到accept()方法的时候进入阻塞状态，需要等待客户端返回连接信息后再将accept()方法返回同时在接收下一个客户端的请求，然后才能连接成功。



#### 编写一个网络应用程序，有客户端和服务器端，客户端向服务器端发送一个字符串，服务器收到该字符串后将其打印到命令行上，然后向客户端返回该字符串的长度，最后，客户端输出服务器端返回的该字符串的长度，分别用TCP和UDP实现



## 数据库

**关系型数据库考点：**

- 架构
- 索引
- 索
- 语法
- 理论范式





数据库的==索==和==索引==是面试的重中之重

### 架构

#### 如何设计一个关系型数据库？

![1551181610168](.\picture\1139.png)

首先需要划分为两大部分，一个是存储部分类似于文件系统，把数据持久化到存储设备当中，另一个是程序实例模块，对存储进行逻辑上的管理，包含：把数据的逻辑关系转化成物理存储关系的==存储管理模块==，优化执行效率的==缓存模块==，将sql语句进行解析的==sql解析模块==，进行日志操作的==日志管理模块==，多用户的==权限划分模块==，==灾难恢复模块==，优化数据查询效率的==索引模块==，使数据库支持并发操作的==锁模块==



### 索引

#### 为什么要使用索引？

很多情况下要避免全表扫描的方式，所以数据库必须引入一种更高效的机制来快速查找数据

#### 什么样的信息能成为索引？

主键、唯一键以及普通键等

#### 索引的数据结构？

- 二叉查找树二分查找算法
- B-Tree结构
- B+-Tree结构
- Hash结构



##### 二叉查找树二分查找算法

我们都知道二叉查找树的查找的时间复杂度是
$$
O（logN）
$$
其查找效率已经足够高了，那为什么还有Ｂ树和Ｂ＋树的出现呢？难道它两的时间复杂度比二叉查找树还小吗？ 

答案当然不是，Ｂ树和Ｂ＋树的出现是因为另外一个问题，那就是磁盘IO；众所周知，IO操作的效率很低，那么，当在大量数据存储中，查询时我们不能一下子将所有数据加载到内存中，只能逐一加载磁盘页，每个磁盘页对应树的节点。造成大量磁盘IO操作（最坏情况下为树的高度）。平衡二叉树由于树深度过大而造成磁盘IO读写过于频繁，进而导致效率低下。 所以，我们为了减少磁盘IO的次数，就你必须降低树的深度，将“瘦高”的树变得“矮胖”。一个基本的想法就是： 
　　（1）每个节点存储多个元素 
　　（2）摒弃二叉树结构，采用多叉树

这样就引出来了一个新的查找树结构 ——多路查找树。 根据AVL给我们的启发，一颗平衡多路查找树(B~树)自然可以使得数据的查找效率保证在O(logN)这样的对数级别上。



##### B-Tree结构

**3阶B树**

![1551663550978](.\picture\1140.png)



一个m阶的B树具有如下几个特征：==B树中所有结点的孩子结点最大值称为B树的阶==，通常用m表示。==一个结点有k个孩子时，必有k-1个关键字才能将子树中所有关键字划分为k个子集==。



- 根结点至少有两个孩子

- 每个中间节点都包含k-1个元素和k个孩子，其中 ceil（m/2） ≤ k ≤ m

- 每一个叶子节点都包含k-1个元素，其中 ceil（m/2） ≤ k ≤ m

- 所有的叶子结点都位于同一层。

- 假设每个非终端结点中包含n个关键字信息，其中

  - Ki（i=1......n）为关键字，且关键字按顺序升序排序K(i-1)<Ki
  - 关键字的个数n必须满足：[ceil(m/2)-1]<=n<=m-1
  - 非叶子结点的指针：P[1],P[2], ... ,P[M]；其中P[1]指向关键字小于K[1]的子树，P[M]指向关键字大于K[M-1]的子树，其它P[i]指向关键字属于（K[i-1],K[i]）的子树

  （翻译：某节点最左边的孩子结点关键字的值均小于该节点最左边的关键字的值，而最右边孩子结点里面关键字的值均大于该结点里关键字的值，该结点的其他孩子结点里的关键字的值的大小均位于离孩子结点指针最近的关键值之间）

  

**其中ceil是取上限函数，即ceil（1.5）=2**



##### B+-Tree结构

![1551666833028](.\picture\1141.png)

![1551665948834](.\picture\1142.png)



结论：

B+树更适合用来做存储索引

- **B+树的磁盘读写代价更低**（B+树的内部结构并没有指向关键字具体信息的指针，即不存放数据，只存放索引信息，因此其内部结点相对于B树更小，如果将所有同一内部结点的关键字存放在同一盘块中，盘块所能容纳的关键字信息也就越多，一次性读入内存中的关键字也就越多，IO读写次数降低）
- **B+树的查询效率更加稳定**（由于内部结点并不是最终指向文件内容的结点，而只是叶子结点关键字的索引，所以任何关键字的查找必须走一条由根结点到叶子节点的路，所有关键字查询的长度相同，每个数据的查询效率也几乎是相同的，稳定在O（LogN）
- **B+树更有利于对数据库的扫描**（B树在解决了磁盘读写的IO问题后，并没有解决元素遍历的效率低下的问题，B+树只需要遍历叶子结点就可以解决对全部关键字信息的扫描，有利于数据库的范围查询）



##### Hash索引

简单地说，**哈希索引就是采用一定的哈希算法**，把键值换算成新的哈希值，检索时不需要类似B+树那样从根节点到叶子节点逐级查找，只需一次哈希算法即可立刻定位到相应的位置，速度非常快。



从上面的图来看，B+树索引和哈希索引的**明显区别**是：

- **如果是等值查询，那么哈希索引明显有绝对优势**，因为只需要经过一次算法即可找到相应的键值；当然了，这个前提是，键值都是唯一的。如果键值不是唯一的，就需要先找到该键所在位置，然后再根据链表往后扫描，直到找到相应的数据；
- 从示意图中也能看到，**如果是范围查询检索，这时候哈希索引就毫无用武之地了**，因为原先是有序的键值，经过哈希算法后，有可能变成不连续的了，就没办法再利用索引完成范围查询检索；
- 同理，**哈希索引也没办法利用索引完成排序**，以及like ‘xxx%’ 这样的部分模糊查询（这种部分模糊查询，其实本质上也是范围查询）；
- **哈希索引也不支持多列联合索引的最左匹配规则**；
- B+树索引的关键字检索效率比较平均，不像B树那样波动幅度大，**在有大量重复键值情况下，哈希索引的效率也是极低的，因为存在所谓的哈希碰撞问题**。

![1551667211618](.\picture\1143.png)



**缺点：**

- **仅仅能满足"="，"IN"，不能使用范围查询**（由于Hash索引是比较经过Hash**运算后**的Hash值，所以只能用于等值的过滤，不能用于基于范围的查询，因为经过相应的Hash算法处理之后的Hash值的大小关系并不能保证和Hash算法前完全一样，上图的John Smith和Sandra Dee指向同一个Hash值）
- **无法被用来避免数据的排序操作**（由于 Hash 索引中存放的是经过 Hash 计算之后的 Hash 值，而且Hash值的大小关系并不一定和 Hash 运算前的键值完全一样，所以数据库无法利用索引的数据来避免任何排序运算）
- **不能利用部分索引键查询**（对于组合索引，Hash 索引在计算 Hash 值的时候是组合索引键合并后再一起计算 Hash 值，而不是单独计算 Hash 值，所以通过组合索引的前面一个或几个索引键进行查询的时候，Hash 索引也无法被利用，B+树是支持组合索引的部分索引的）
- **不能避免表扫描**（前面已经知道，Hash 索引是将索引键通过 Hash 运算之后，将 Hash运算结果的 Hash 值和所对应的行指针信息存放于一个 Hash 表中，由于不同索引键存在相同 Hash 值，所以即使取满足某个 Hash 键值的数据的记录条数，也无法从 Hash 索引中直接完成查询，还是要通过访问表中的实际数据进行相应的比较，并得到相应的结果）
- **遇到大量Hash值相等的情况后性能并不一定就会比B树索引高**（对于选择性比较低的索引键，如果创建 Hash 索引，那么将会存在大量记录指针信息存于同一个 Hash 值相关联。这样要定位某一条记录时就会非常麻烦，会浪费多次表数据的访问，而造成整体性能低下）



##### BitMap索引

Oracle数据库会用到



数据库索引总结：B+树索引最常用，Hash索引和BitMap索引比较小众。



#### 密集索引和稀疏索引的区别？

**密集索引的定义**：叶子节点保存的不只是键值，还保存了位于同一行记录里的其他列的信息，由于密集索引决定了表的物理排列顺序，一个表只有一个物理排列顺序，所以一个表只能创建一个密集索引

**稀疏索引的定义**：叶子节点仅保存了键位信息以及该行数据的地址，有的稀疏索引只保存了键位信息及其主键



**区别：**

- 密集索引文件中的每个搜索码值都对应一个索引值
- 稀疏索引文件只为索引码的某些值建立索引项



![1551788706355](.\picture\1144.png)

对MySql做具体分析：MySql主要有==两种==存储引擎，一种是==MyISAM存储引擎==，一种是==InnoDB存储引擎==

**MyISAM存储引擎**：不管是主键索引，唯一键索引还是普通索引都是稀疏索引

**InnoDB存储引擎**：有且只有一个密集索引。密集索引的选取规则如下：

- 若主键被定义，则主键作为密集索引
- 如果没有主键被定义，该表的第一个唯一非空索引则作为密集索引
- 若不满足以上条件，innodb内部会生成一个隐藏主键（密集索引）

- 非主键索引存储相关键位和其对应的主键值，包含两次查找

InnoDB必须包含一个主键，这个主键必须作为唯一的密集索引而存在，非主键索引的叶子结点并不存储行数据的物理地址，而是存储的是该行的主键值，非主键索引包含了两次查找，一次是查找次级索引自身，一次是查找主键。



InnoDB采用的是密集索引，将主键组织到一棵B+树中，而行数据就存储在叶子结点上，==因为InnoDB的主键索引和对应的数据是保存在同一个文件当中的==，所以检索的时候会把主键和主键对应的数据同时加载到内存当中，当使用where id=14进行查找即可运用B+树的查询算法查找到主键和对应的数据，若对稀疏索引进行条件筛选，则需经历两个步骤，第一步：在稀疏索引的B+树中检索该键，第二步：得到主键后再去B+树中查询该主键所对应的数据。



MyISAM采用的是稀疏索引，MyISAM的两棵B+树的结点结构完全一致，只是叶子结点存储的数据不同而已，主键索引B+树存储了主键，辅助键索引B+树存储了辅助键，表数据存储在独立的地方，==也就是索引和数据是分开存储的==，这两棵B+树的叶子节点都使用了一个地址指向真正的表数据，对于表数据来说，这两个键没有任何差别，由于索引数是独立的，通过辅助键索引访问表数据无需访问主键索引

![1551790631034](.\picture\1145.png)



#### 如何定位优化慢查询sql？

- 根据慢日志定位慢查询sql
- 使用explain等工具分析sql
- ==修改sql或者尽量让sql走索引==



**一个简单数据库调优的例子**



查询和慢日志相关的配置信息

```java
SHOW VARIABLES LIKE '%quer%';
```

![1552438852386](.\picture\1146.png)

查询系统状态中慢查询的数量

```java
SHOW STATUS LIKE '%slow_queries%';
```

![1552438944654](.\picture\1147.png)





![1551833679104](.\picture\1148.png)

![1551833896755](.\picture\1149.png)



==用explain关键字进行原因查询：==

![1552445842130](.\picture\1150.png)

![1552445878287](.\picture\1151.png)

关键字段：

- **type**：表示mysql找到数据行的方式

性能从最优到最差排序：假如看到index和all而且有慢查询的话，那么就需要调优了

![1552445995968](.\picture\1152.png)

- **extra**：

![1552446136026](.\picture\1153.png)



![1552446862321](.\picture\1154.png)

name加上索引后，查询结果是：

![1552446888239](.\picture\1155.png)

![1552447011077](.\picture\1156.png)

以上结果为三次sql语句：name（不是索引），account（是索引），name第二次（把name加上索引）



![1552456356804](.\picture\1157.png)

MySQL查询优化器有几个目标，但是其中最主要的目标是**尽可能地使用索引**，并且使用==最严格==的索引来**消除尽可能多的数据行**。你的最终目标是提交SELECT语句查找数据行，而不是排除数据行。优化器试图排除数据行的原因在于它排除数据行的速度越快，那么找到与条件匹配的数据行也就越快。**因此查询优化器会根据会根据它的一些分析和判断的标准来决定走哪一个索引**。

**这里的原因是主键是密集索引，密集索引的叶子结点把其他列的信息也存放到了叶子结点当中，数据都放在一起了，查询起来比稀疏索引效率低，因为稀疏索引只存储了关键字和主键的值，这样在内存中就有更多的主键值来去做count，以此来节约性能**



强制走主键索引

![1552456923635](.\picture\1158.png)



**结论；查询操作走主键比一定比走其他索引快，具体问题具体分析**



#### 解释联合索引和最左匹配原则的成因？

**联合索引**：





**最左匹配原则**：

1. 最左前缀匹配原则，非常重要的原则，mysql会一直向右匹配直到遇到范围查询(>、<、between、like)就停止匹配，比如a = 1 and b = 2 and c > 3 and d = 4 如果建立(a,b,c,d)顺序的索引，d是用不到索引的，如果建立(a,b,d,c)的索引则都可以用到，a,b,d的顺序可以任意调整。

2. =和in可以乱序，比如a = 1 and b = 2 and c = 3 建立(a,b,c)索引可以任意顺序，mysql的查询优化器会帮你优化成索引可以识别的形式。



**最左匹配原则的成因**

mysql创建复合索引的成因就是对第一个索引字段的数据进行排序，在这个排序的基础上，再对第二个索引字段进行排序，所以第一个字段是绝对有序的，第二个字段是无序的，==因此直接使用第二个字段是用不到索引的==。复合索引的结构与电话簿类似，人名由姓和名构成，电话簿首先按姓氏对进行排序，然后按名字对有相同姓氏的人进行排序。如果您知 道姓，电话簿将非常有用；如果您知道姓和名，电话簿则更为有用，但如果您只知道名不姓，电话簿将没有用处。
所以说创建复合索引时，应该仔细考虑列的顺序。对索引中的所有列执行搜索或仅对前几列执行搜索时，复合索引非常有用；仅对后面的任意列执行搜索时，复合索引则没有用处。



#### 索引是建立的越多越好吗？

- 数据量小的表不需要建立索引
- 数据变更需要维护索引，更多的索引意味着更多的维护成本
- 更多的索引意味着更多的空间





### 锁

#### 锁模块

常见问题：

- MyISAM和InnoDB关于锁方面的区别是什么
- 数据库事务的四大特性
- 事务隔离级别以及各级别下的并发访问问题
- InnoDB可重复读隔离级别下如何避免幻读
- RC，RR级别下的InnoDB的非阻塞读如何实现



##### MyISAM和InnoDB关于锁方面的区别是什么？

- **MyISAM默认用的是表级锁**，不支持行级锁
- **InnoDB默认用的是行级锁**，也支持表级锁

**（表级锁会锁住整张表，行级锁会锁住整行）**

- MyISAM适用的场景
  - 频繁执行全表count语句
  - 对数据库进行增删改查的频率不高，查询非常频繁
  - 没有事务
- InnoDB适用场景
  - 数据增删改查都相当频繁
  - 可靠性比较高，要求支持事务







###### **新知识：**

- MyISAM不支持事务（transaction），表级锁的情况不好模仿，所以演示的时候需要插入大量的数据，分别用不同的会话（session）去操作这张表

- InnoDB使用的是==**二段锁**==，加锁和解锁是分为两个步骤来执行的（即先对同一个事务里的一批操作分别进行加锁，然后commit的时候再对加上的锁进行统一的解锁，所以要模拟并发的情况的话就需要加上begin transaction）
  - ![1552965024818](.\picture\1159.png)
- 共享锁（读锁）和排他锁（写锁）
- 会话和事务
- InnoDB引擎，行锁和意向锁





###### 会话和事务：

**会话**，即==session==，当你使用工具如sqlplus或者toad执行连接，**连接到某个数据库的时候，就开启了一个会话，直到你关闭这次连接，这个会话才算结束。**



**事务**，即==transaction==，是一个由多条SQL语句组成的工作逻辑单元，这些语句要么全部执行成功，要么全部不执行。只有commit，rollback，或者关闭工具的情况下，事务才会结束。当一个事务结束之后，下一个可执行的SQL语句自动开启一个新的事务。事务具有4个特性·：**原子性**，**一致性**，**隔离性**，**持久性**。这里不具体说。





###### **共享锁（读锁）和排他锁（写锁）：**

mysql锁机制分为**表级锁**和**行级锁**，本文就和大家分享一下我对mysql中行级锁中的共享锁与排他锁进行分享交流。

**共享锁又称为读锁**，简称S锁，顾名思义，共享锁就是多个事务对于同一数据可以共享一把锁，都能访问到数据，但是只能读不能修改。

**排他锁又称为写锁**，简称X锁，顾名思义，排他锁就是不能与其他所并存，如一个事务获取了一个数据行的排他锁，其他事务就不能再获取该行的其他锁，包括共享锁和排他锁，但是获取排他锁的事务是可以对数据就行读取和修改。

对于共享锁大家可能很好理解，就是多个事务只能读数据不能改数据，对于排他锁大家的理解可能就有些差别，我当初就犯了一个错误，以为排他锁锁住一行数据后，其他事务就不能读取和修改该行数据，其实不是这样的。排他锁指的是一个事务在一行数据加上排他锁后，其他事务不能再在其上加其他的锁。mysql InnoDB引擎默认的修改数据语句，update,delete,insert都会自动给涉及到的数据加上排他锁，select语句默认不会加任何锁类型，==**如果加排他锁可以使用select ...for update语句，加共享锁可以使用select ... lock in share mode语句**==。所以加过排他锁的数据行在其他事务种是不能修改数据的，也不能通过for update和lock in share mode锁的方式查询数据，但可以直接通过select ...from...查询数据，因为普通查询没有任何锁机制。



###### **InnoDB引擎，行锁和意向锁：**

InnoDB提供了两种锁，一种是行锁另一种就是意向锁，其中行锁是针对当我们查询或者更新时使用到了索引的时候(这个使用索引不是我们在DDL中使用了索引，而是InnoDB根据默认的索引操作，或者是根据我们设置的索引规则，InnoDB在执行DDL语句的时候确实使用了索引)，那么这个时候就会使用行锁。当我们的DDL语句没有使用索引，而是进行的表的扫描的时候，这个时候InnoDB就会使用表锁(意向锁是一种页级、表级锁)。

**行锁**：

InnoDB提供了行锁，当我们使用索引对数据库进行操作的时候，InnoDB就会使用行锁，这个时候锁定的是一行或者是一个范围，如果我们使用的唯一索引，那么锁定的一行，如果我们使用的一般索引，那么锁定的就是一个范围。InnoDB提供了两种形式的行锁：

| 锁           | 功能                               |
| ------------ | ---------------------------------- |
| 共享锁(S 锁) | 对于读采用共享锁的方式             |
| 排它锁(X 锁) | 对于更新或者插入的方式会使用排他锁 |

**共享锁和排他锁的兼容情况：**

| /            | 共享锁(S 锁) | 排它锁(X 锁) |
| ------------ | ------------ | ------------ |
| 共享锁(S 锁) | 兼容         | 不兼容       |
| 排他锁(X 锁) | 不兼容       | 不兼容       |

**表锁：**

在一个事务中，如果我们使用的DDL语句中没有使用索引，那么这个时候InnoDB就会使用页级或者是表级意向锁。







###### 实践所得出的结论：

以mysql的InnoDB引擎为例子（MyISAM的与InnoDB的区别就是它锁住的是整张表）：

情况一：

**一个事务加上了排他锁，只要是加锁的语句都会阻塞，不加锁的select语句可以执行**

情况二：

**一个事务获取了共享锁，在其他查询中也只能加共享锁或不加锁**

情况三：

**mysql InnoDb引擎中update,delete,insert语句自动加排他锁**

情况四：

**当不走索引的时候，整张表都会被锁住，InnoDB在sql语句没有用到索引的时候所用的是表级锁，sql用到索引的时候使用的是行级锁或者是GAP锁（走普通非唯一索引时候所用到的）**

情况五：

**表级锁与索引无关**



##### 数据库事务的四大特性

- 原子性

- 一致性

- 隔离性

- 持久性



##### 事务隔离级别以及各级别下的并发访问问题

**数据库事务的隔离级别有4个，由低到高依次为**

- ==Read uncommitted（读未提交）==

  - 最低的隔离级别。一个事务可以读取另一个事务并未提交的更新结果。

- ==Read committed （读提交）==

  - **Oracle的默认级别**，大部分数据库采用的默认隔离级别。一个事务的更新操作结果只有在该事务提交之后，另一个事务才可以读取到同一笔数据更新后的结果
  - 针对当前读，**RC隔离级别保证对读取到的记录加锁 (记录锁)**，存在幻读现象。

- ==Repeatable read （可重复读）==

  - **mysql的InnoDB的默认级别**，==在整个一条事务的过程中==，对同一笔数据的读取结果是相同的，不管其他事务是否在对共享数据进行更新，也不管更新提交与否。
  - 针对当前读，**RR隔离级别保证对读取到的记录加锁 (记录锁)，同时保证对读取的范围加锁，新的满足查询条件的记录不能够插入 (间隙锁)**，不存在幻读现象。

- ==Serializable （序列化）==

  - 从MVCC并发控制退化为基于锁的并发控制。不区别快照读与当前读，所有的读操作均为当前读，读加读锁 (S锁)，写加写锁 (X锁)。

    Serializable隔离级别下，读写冲突，因此并发度急剧下降，在MySQL/InnoDB下不建议使用。

  - 最高隔离级别。所有事务操作依次顺序执行。注意这会导致并发度下降，性能最差。通常会用其他并发级别加上相应的并发锁机制来取代它。



**不同事务级别带来的并发问题：**

- ==脏读==

  - 脏读发生在一个事务A读取了被另一个事务B修改，但是还未提交的数据。假如B回退，则事务A读取的是无效的数据。这跟不可重复读类似，但是第二个事务不需要执行提交。 

- ==不可重复度==

  - 事务A多次读取同一数据，事务B在事务A多次读取同一事务的时候对数据进行更新并且提交，导致事务A多次读取同一事务的时候数据不一致

- ==幻读==

  - 在可重复读中，该sql第一次读取到数据后，就将这些数据加锁（悲观锁），其它事务无法修改这些数据，就可以实现可重复读了。但这种方法却无法锁住insert的数据，所以当事务A先前读取了数据，或者修改了全部数据，事务B还是可以insert数据提交，这时事务A就会发现莫名其妙多了一条之前没有的数据，这就是幻读，发生的情况：没有范围锁。
  - 幻读不能通过行锁来避免。需要Serializable隔离级别 ，读用读锁，写用写锁，读锁和写锁互斥，这么做可以有效的避免幻读、不可重复读、脏读等问题，但会极大的降低数据库的并发能力。

![1553153877430](E:\Typora文件 公司电脑\图片\1160.png)

**事务隔离级别越高，安全性越高，串行化执行越严重，降低了数据库地并发度，因此要根据业务的需要去设置事务的隔离级别**，但是MySQL、ORACLE、PostgreSQL等成熟的数据库，出于性能考虑，都是使用了以乐观锁为理论基础的MVCC（多版本并发控制）来实现。



Mysql的InnoDB引擎在Reaptable的情况下避免了幻读的产生，理应是在Serializable的条件下才能避免幻读，但是它通过一种巧妙地方式去避免了幻读。这种方式是什么呢？





##### RC，RR级别下的InnoDB的非阻塞读如何实现？

（==**非阻塞读就是快照读**==）

- 数据行里的DB_TRX_ID、DB_ROLL_PTR、DB_ROW_ID字段（每行数据除了存储的字段外，还有其他的字段，其中最重要的就是这三个字段）
- undo日志
- read view



**新概念：**

涉及到的概念：

**当前读和快照读**

**概念：**

**快照读**

读取的是记录数据的可见版本（可能是过期的数据），不用加锁

**当前读**

读取的是记录数据的最新版本，并且当前读返回的记录都会加上锁，保证其他事务不会再并发的修改这条记录
 概念说的比较虚，也不好理解，接着举一个例子吧，假设你开启了两个事务，分别是A和B，这里有个张表，user表，里面有四条数据

![1553173463022](.\picture\1161.png)

**1、==快照读==（不加锁的非阻塞读 select）**

==这个不加锁的条件是事务隔离级别不为Serializable的前提下成立的==，在Serializable的条件下面快照读select==退化==为当前读select...lock in share mode

当你执行select *之后，在A与B事务中都会返回4条一样的数据，这是不用想的，当执行select的时候，innodb默认会执行快照读，相当于就是给你目前的状态找了一张照片，以后执行select 的时候就会返回当前照片里面的数据，当其他事务提交了也对你不造成影响，和你没关系，这就实现了可重复读了，那这个照片是什么时候生成的呢？==不是开启事务的时候，是当你第一次执行select的时候==，也就是说，当A开启了事务，然后没有执行任何操作，这时候B insert了一条数据然后commit,这时候A执行 select，那么返回的数据中就会有B添加的那条数据......之后无论再有其他事务commit都没有关系，因为照片已经生成了，而且不会再生成了，以后都会参考这张照片。

**2、==当前读==（update、insert、delete 、select...lock in share mode（前四个是共享锁）、select...for update（这个是排它锁））**

当你执行这几个操作的时候默认会执行当前读，也就是会读取最新的记录，也就是别的事务提交的数据你也可以看到，这样很好理解啊，假设你要update一个记录，另一个事务已经delete这条数据并且commit了，这样不是会产生冲突吗，所以你update的时候肯定要知道最新的信息啊。 我在这里介绍一下update的过程吧，首先会执行当前读，然后把返回的数据加锁，之后执行update。加锁是防止别的事务在这个时候对这条记录做什么，默认加的是排他锁，也就是你读都不可以，这样就可以保证数据不会出错了。但注意一点，就算你这里加了写锁，别的事务也还是能访问的，是不是很奇怪？数据库采取了一致性非锁定读，别的事务会去读取一个快照数据。



 innodb默认隔离级别是RR， 是通过MVVC来实现了，读方式有两种，执行select的时候是快照读，其余是当前读，所以，mvvc不能根本上解决幻读的情况



**实际操作的结论：**



![1553217824747](.\picture\1162.png)



**在read committed（RC）的隔离级别在下，当前读和快照读所读到的版本是一致的，都是最新的数据版本**

**在repeatable read（RR）的隔离级别下，快照读==有可能==读到数据的历史版本（创建快照读的时机决定了数据的版本），当前读读到数据的最新版本**



delete操作在InnoDB看来也是一次update操作，即更新行中的特殊位，将行表示为deleted，并非真正的去删除，而是将该行标识为隐藏列

**DB_TRX_ID**：用来标识最近一次对本行记录做修改事务的标识符，即最后一次修改本行数据的事务ID



**DB_ROLL_PTR**：回滚指针



**DB_ROW_ID**：行号，包含一个随着新行插入而单调递增的行ID，当由InnoDB自动产生聚集索引时，聚集索引会包括这个行ID的值，否则这个行ID不会出现在任何索引中（如果InnoDB的表既没有主键也没有唯一键的话，InnoDB会自动为我们隐式地创建一个自增的隐藏主键字段，也就是DB_ROW_ID）

光有以上三个字段并不能实现快照读，还需要undo日志

**undo日志**：**撤销日志**，当一些更改在执行一半时，发生意外，而无法完成，则可以根据撤消日志恢复到更改之前的壮态。当我们对记录做出了变更操作时，就会产生undo记录，undo记录中存储的是老版本的数据，当一个旧的事务需要读取数据时，为了能够读取到老版本的数据，需要顺着undo链找到满足其可见性的记录。

undo日志分为insert undo日志和update undo日志

**insert undo日志**：事务对insert新记录所产生的undo log，只在事务回滚时需要，并且在事务提交后就可以立即丢弃

**update undo日志**：事务对记录实施delete或者是update操作时所产生的undo log，不仅是在事务回滚时需要，在快照读的时候也需要，所以不能随便删除，只有当数据库所使用的快照中不涉及该日志记录，对应的回滚日志才会被删除。



事务A修改Field2的值12~32的流程：

- 用排它锁锁定改行
- 把改行修改前的值拷贝一份到undo日志里面
- 修改当前行中中Field2中的值，填写DB_TRX_ID（事务ID），使用回滚指针指向undo log中修改前的行

![1553418787779](.\picture\1163.png)



事务B修改完了FIeld3的值13~45

![1553418811684](.\picture\1164.png)



**read view**：主要是用来做可见性判断的，即当我们去执行快照读select的时候，会针对我们查询的数据创造出一个read view来决定当前事务所看到的数据是哪个版本的数据（有可能是当前最新版本的数据，也有可能是undo log中某一个版本的数据），read view遵循一个可见性算法，主要是将要修改的数据的DB_TRX_ID取出来与系统其它活跃DB_TRX_ID做对比，如果大于或者等于的话，根据DB_ROLL_PTR找到小于的为止，保证了获取到的数据版本是当前最稳定的数据版本。



RC，RR级别下的InnoDB的非阻塞读如何实现的**结论**：

正是因为生成时机的不同，造成了RC，RR两种隔离级别的不同可见性。在RR隔离级别下，session在start transaction之后的第一条快照读会创建一个快照即read view，将当前系统中活跃的其它事务记录起来，此后再调用快照读的时候还是用的是同一个read view。而在RC隔离级别下，事务中每条select语句，也就是每次调用快照读的时候都会创建一个新的快照。

正是因为以上三个因素，才使得InnoDB在RC和RR隔离级别下面支持快照读（非阻塞读），而读取事务的非阻塞也就是所谓的MVCC，而InnoDB实现的非阻塞读机制实现了==仿造版的MVCC==

**MVCC:** 多版本并发控制（MVCC,Multiversion Currency Control），读不加锁，读写不冲突，极大地增加了系统的并发性能

**为什么仅仅实现了伪MVCC机制呢？**

因为并没有实现多版本共存，undo日志中的内容只是串行化的结果，记录了多个事务的过程，不属于多版本共存。





##### InnoDB可重复读隔离级别下如何避免幻读？

- 表象：**快照读**（==非阻塞读==）--伪MVCC来避免我们看到幻行，当然前提是在RR级别下。
- 内在：next-key锁（行锁+gap锁）--真正防止幻读发生的



第一条快照读上面已经解释过了

现在讨论next-key锁（行锁+gap锁）

**gap锁：**

**什么是gap？**

gap就是索引树中插入新纪录的空隙

**什么是gap lock？**

间隙锁，即锁定一个范围，但不包括记录本身，gap锁的目的是防止同一事务的两次当前读出现幻读的情况，gap锁在RC以及更低的事务隔离级别下是没有的，这就是在Read committed和Read uncommitted隔离条件下无法避免幻读的原因，而在RR和Serializable隔离条件下是支持gap锁的。



现在讨论RR隔离条件下的gap锁的情况：

**在RR条件下，对主键索引或者唯一索引会用gap锁吗？**

视情况而定

- **如果where条件全部命中，则不会用gap锁，只会加记录锁**

![1553439660499](.\picture\1165.png)

当获取的记录具有唯一性（主键或者唯一键），例如上图中的id为唯一键，当事务A去操作这条语句的时候，此时事务B新增的那条信息必然也会在这个当前读的范围之外，并不会产生幻读现象，所以此时加行锁就足够了，需要注意的是：

==**加锁的时候，如果我们走的是主键之外的索引，那么我们需要对当前索引和主键索引对应的记录都上锁**==

此组合中，id是unique索引，而主键是name列。此时，加锁的情况由于组合一有所不同。由于id是unique索引，因此delete语句会选择走id列的索引进行where条件的过滤，在找到id=9的记录后，首先会将unique索引上的id=9索引记录加上X锁，同时，会根据读取到的name列，回主键索引(聚簇索引)，然后将聚簇索引上的name = ‘d’ 对应的主键索引项加X锁。为什么聚簇索引上的记录也要加锁？试想一下，如果并发的一个SQL，是通过主键索引来更新：update t1 set id = 100 where name = ‘d’; 此时，如果delete语句没有将主键索引上的记录加锁，那么并发的update就会感知不到delete语句的存在，违背了同一记录上的更新/删除需要串行执行的约束。



- **如果where条件部分命中或者全不命中，则会加上gap锁**
  - 如果是部分命中的话，那么只会在部分命中的区域内加gap锁，在区域外不加gap锁



**gap锁会用在==非唯一索引==或者==不走索引==的当前读中**

非唯一索引：

![1553437631401](.\picture\1166.png)

上表中显示的id是非唯一索引，name是主键，可以见得红色区域gap锁的位置





表结构：

![1553438621840](.\picture\1167.png)



事务一：

![1553438752516](.\picture\1168.png)



事务二：

![1553437991453](.\picture\1169.png)

结论：由上面可知，加gap锁的范围是(6,11]，由于B+树的主键索引的叶子节点按照首字母顺序排列，所以倒数第二行语句所插入的数据是(6,11]开外的，所以没有被gap锁block住，而最后一行语句所插入的数据是dd，按照首字母排序是在(6,11]内的，所以被gap锁block住了



不走索引：

![1553439012010](.\picture\1170.png)

不走索引的情况会对所有的gap都上锁，相对于表锁，这种gap锁是大大降低数据库效率的，应当避免



### 复杂的语法讲解

#### 关键语法：

- **GROUP BY**
- **HAVING**
- 统计相关的**特殊函数**：**COUNT，SUN，MAX，MIN，AVG**



##### Group By

**作用**：根据给定数据列的每个成员对查询结果进行分组统计，最终得到一个分组汇总表

- select子句中的列名必须为分组或列函数（如果用group by，那么你的select语句中选出的列要么是你group by里所用到的列，要么就是带有之前我们说的如sum min等列函数的列，不能有其他列的存在）
- 列函数对于group by子句顶一个每个组各返回一个结果

（group by在执行的时候就是通过构造temporary表存储字段的，此处可以通过在sql语句前面添加explain关键字来查询）





**group by练习：**

![1553652521537](.\picture\1171.png)



![1553652614327](.\picture\1172.png)



![1553652651799](.\picture\1173.png)





![1553652702622](.\picture\1174.png)



- 查询所有同学的学号、选课数、总成绩

```sql
select student_id,count(course_id),sum(score) from score group by student_id
```

输出结果：

![1553652957233](.\picture\1175.png)

- 查询所有同学的学号、姓名、选课数、总成绩

```sql
select s.student_id,stu.name,count(s.course_id),sum(s.score) from score s,student stu where s.student_id=stu.student_id group by s.student_id
```

输出结果：

![1553653351805](.\picture\1176.png)





##### Having

- 通常与group by子句一起使用
- where过滤行，having过滤组
- 出现在同一sql的顺序：where > group by > having，调整顺序会报错



having练习：

- 查询平均成绩大于60分的同学的学号和平均成绩

```sql
select student_id,avg(score) from score group by student_id having avg(score)>60
```

输出结果：

![1553653860432](.\picture\1177.png)



- 查询没有学全所有课得同学得学号、姓名

```sql
select stu.student_id,stu.name from student stu,score s where stu.student_id=s.student_id group by s.student_id having count(*)<(select count(*)from course)
```

输出结果：

![1553654342647](.\picture\1178.png)





## Java原理

### 谈谈你对Java的理解？

- 平台无关性
- GC
- 语言特性（泛型，反射，Lambda表达式）
- 面向对象（封装，继承，多态）
- 类库
- 异常处理



### Java是如何做到一次编译，到处执行的呢？

- 编译时

将源码编译生成二进制字节码，再存入.class文件当中

- 运行时

**编译运行一个java文件**

![1553685779838](.\picture\1179.png)

javac指令：编译完之后生成一个.class文件

java指令：让jvm去解析对应的.class文件，将里面的字节码内容加载至内存，并最终转换成本操作系统能够识别的机器码去执行

**javap：**

==javap是JDK自带的反汇编器，可以查看java编译器为我们生成的字节码==



源代码：

```java
public class ByteCodeSimple {
    public static void main(String[] args) {
        int i=1,j=5;
        i++;
        ++j;
        System.out.println(i);
        System.out.println(j);
    }
}
```

javap之后的：

![1553687753142](.\picture\1180.png)



- 表示从ReverseInteger.java编译而来

- 编译器生成的缺省构造函数的内容，对应的是这个无参构造函数

```java
 public shi.ReverseInteger()；
```

- Code表示无参构造函数里面需要执行的内容了

- aload_0：表示对this这个句柄进行操作

- invokespecial #1：调用父类的构造方法super

- return：退出构造函数

==可以学到：当我们不指定一个类的构造函数的时候，编译器会为我们生成一个不带参的构造函数==

- 来看main函数，接收的是字符串类型的数组

Code里涉及到栈的操作

- iconst_1：把常量1放到栈顶

- istore_1：将栈顶的值放到局部变量1（i）当中

- iconst_5：把常量5放到栈顶

- istore_2：将栈顶的值放到局部变量2（j）当中

- iinc 1,1：将变量1加1

- iinc 2,1：将变量2加1

- getstatic #2：获取PrintStream的静态域，并压入栈顶

- iload_1：将本地变量2的值推送至栈顶

- invokevirtual #3：调用PrintStream.println打印i的值

- getstatic #2：后面和i一样

- iload_2

- invokevirtual #3

- return



**这些指令就是java虚拟机所能理解的字节码**



![1553688892221](.\picture\1181.png)



### 为什么JVM不直接将源码解析成机器码去执行？

- 如果是这样，我们每次执行的时候需要进行各种语法，句法，语义的检查，即每次执行的时候这些语义分析的结果都不会被保留下来，都要重新编译分析，整体性能受到影响，中间字节码的生成可以保证多次执行程序都不需要进行各种校验和补全的（**准备工作**）
- 字节码也可以由其他语言生成，如**Groovy，Clojure，Scala**。需要注意的事，既然这些语言可以编译成字节码，也就可以被Java或其他JVM语言调用（**兼容性**）



### JVM如何加载.class文件



![1553824050899](.\picture\1182.png)



需要知道有四个东西：

- **class loader** 
  - 类加载器的作用是加载类文件到内存，比如编写一个HelloWord.java 程序，然后通过javac 编译成class 文件，那怎么才能加载到内存中被执行呢？Class Loader 承担的就是这个责任，那不可能随便建立一个.class 文件就能被加载的，Class Loader 加载的class 文件是有格式要求
- **runtime data area**
  - JVM内存结构模型，
  - 运行数据区是整个JVM 的重点。我们所有写的程序都被加载到这里，之后才开始运行，Java 生态系统如此的繁荣，得益于该区域的优良自治。
- **execution engine**
  - 执行引擎也叫做解释器(Interpreter) ，负责解释命令，提交操作系统执行

- **native interface** 
  - 本地接口的作用是融合不同的编程语言为Java 所用，它的初衷是融合C/C++ 程序，Java 诞生的时候是C/C++ 横行的时候，要想立足，必须有一个聪明的、睿智的调用C/C++ 程序，于是就在内存中专门开辟了一块区域处理标记为native 的代码，它的具体做法是Native Method Stack 中登记native 方法，在Execution Engine 执行时加载native libraies 。目前该方法使用的是越来越少了，除非是与硬件有关的应用，比如通过Java 程序驱动打印机，或者Java 系统管理生产设备，在企业级应用中已经比较少见，因为现在的异构领域间的通信很发达，比如可以使用Socket 通信，也可以使用Web Service 等等，不多做介绍。



回答：通过classloader把==符合格式要求==的.class文件加载到内存中，通过execution engine去解析classloader中的==字节码==并提交给操作系统去执行。



### 什么是java的反射？

Java反射就是在运行状态中，对于任意一个类，都能够知道这个类的所有属性和方法；对于任意一个对象，都能够调用它的任意方法和属性，这种动态获取信息以及动态调用对象方法的功能称为java语言的反射机制。

**写一个反射的例子：**



**getmethod和getdeclaredmethod的区别？**



**public Method[] getMethods()**返回某个类的所有公用（public）方法包括其继承类的公用方法，当然也包括它所实现接口的方法。
**public Method[] getDeclaredMethods()**对象表示的类或接口声明的所有方法，包括公共、保护、默认（包）访问和私有方法，但不包括继承的方法。当然也包括它所实现接口的方法



### 类从编译到执行的过程

- JVM将Robot.java源文件编译为Robot.class字节码文件
- ClassLoader将字节码转换为JVM中的Class<Robot>对象
- JVM利用Class<Robot>对象实例化Robot对象



### 谈谈ClassLoader

![1555227841110](.\picture\1183.png)



**ClassLoader的种类：**

**BootStrap ClassLoader：**==C++编写（用户在编译器里看不到，必须到JVM中去看）==，称为**==启动类加载器==**，是Java类加载层次中最顶层的类加载器，负责**加载JDK中的核心类库（java.*）**，如：rt.jar、resources.jar、charsets.jar等。

**Extension ClassLoader：**==Java编写（在编译器里面看得到）==，称为**==扩展类加载器==**，负责加载**Java的扩展类库（javax.*）**，默认加载JAVA_HOME/jre/lib/ext/目下的所有jar。

- 加载路径：

```java
System.getProperty("java.ext.dirs")
```

**App ClassLoader：**==Java编写（在编译器里面看得到）==，称为**==系统类加载器==**，负责加载应用程序classpath目录下的所有jar和class文件。

- 加载路径：

```java
System.getProperty("java.class.path")
```

**自定义ClassLoader：**==Java编写（在编译器里面看得到）==，==定制化加载==



注意： 除了Java默认提供的三个ClassLoader之外，用户还可以根据需要定义自已的ClassLoader，而这些自定义的ClassLoader都必须继承自java.lang.ClassLoader类，也包括Java提供的另外二个ClassLoader（Extension ClassLoader和App ClassLoader）在内，但是Bootstrap ClassLoader不继承自ClassLoader，因为它不是一个普通的Java类，底层由C++编写，已嵌入到了JVM内核当中，当JVM启动后，Bootstrap ClassLoader也随着启动，负责加载完核心类库后，并构造Extension ClassLoader和App ClassLoader类加载器。



函数编写：

**写一个自定义的classloader**（有源码，看课程源码）

关键函数：

```java
protected Class<?> findClass(String name) throws ClassNotFoundException {
    throw new ClassNotFoundException(name);
}
```

```java
protected final Class<?> defineClass(byte[] b, int off, int len)
    throws ClassFormatError
{
    return defineClass(null, b, off, len, null);
}
```

**总结：**



findClass()就是根据名称或者位置去加载.class字节码，然后它会调用defineClass()去解析定义.class字节流，然后返回Class对象



代码思路：

先写一个class类，然后通过javac对这个类进行编译生成.class文件，然后自定义一个ClassLoader，去到这个类路径下读取这个类的文件流，解析，返回class对象



### 类的加载方式

- **隐式加载（无需调用类对象的newInstance来获取对象的实例）**
  - 由 new 关键字创建一个类的实例
  - new支持传入参数，而newInstance不支持传入参数，如果newInstance需要传参，则需要调用反射
- **显式加载（调用类对象的newInstance来获取对象的实例）**
  - 调用 Classloder.loadClass() 方法
  - 调用 Class.forName() 方法



### 类的装载过程

- 加载
- 链接
- 初始化

![1555476215279](.\picture\1184.png)

### loadClass和forName的区别？

- **相同点：**
  - 都能在运行时知道加载类的所有属性和方法

- **不同点：**
  - Classloder.loadClass()得到的class是没有链接的，只停留在第一步
  - Class.forName()得到的class是已经初始化完成的，执行完上述三步了                             

**这种区别的应用场景：**

**forName：**

因为Driver里面是有静态代码段的，所以需要调用forName来创建数据库驱动

```java
Class.forName("com.mysql.jdbc.Driver");
```

**loadClass：**

在SpringIOC中的资源加载器获取要读入Bean的配置文件的时候，为了加快初始化速度，大量使用延迟加载（lazy loading），等真正使用的时候再初始化





### 你了解Java内存模型吗？



![1555634082717](.\picture\1185.png)

地址空间划分：

- 内核空间
- 用户空间（Java进程实际运行时使用的内存空间）



![1555634354594](.\picture\1186.png)





#### Java内存模型

##### 程序计数器

- 当前线程所执行的字节码行号指示器
- 改变计数器的值来选取下一条需要执行的字节码指令
- 和线程是一对一的关系

- 记录正在执行的虚拟机字节码指令的地址（如果正在执行的是本地方法（native方法）则为空（Undefined））
- 不会发生内存泄漏

##### Java 虚拟机栈

- Java 虚拟机栈是Java方法执行的内存模型
- 每个 Java 方法在执行的同时会创建一个栈帧用于存储局部变量表、操作数栈、常量池引用等信息。从方法调用直至执行完成的过程，就对应着一个栈帧在 Java 虚拟机栈中入栈和出栈的过程。
  - 局部变量表：包含方法执行过程中的所有变量
  - 操作数栈：在执行字节码指令时被用到，这种方式类似于原生CPU寄存器，大部分JVM字节码把时间花费在操作数栈的操作上，包括入栈，出栈，复制，交换，产生消费变量

<div align="center"> <img src="https://gitee.com/CyC2018/CS-Notes/raw/master/docs/pics/ff5b89ac-798e-4fbc-b0ce-da2fc2358570.jpg"/> </div><br>

程序实例：

```java
public class ByteCodeSample {
    public static int add(int a, int b) {
        int c = 0;
        c = a + b;
        return c;
    }
}
```

**执行add（1，2）**

![1555635632186](.\picture\1187.png)

结论：局部变量表为操作数栈提供必要的数据支撑



可以通过 -Xss 这个虚拟机参数来指定每个线程的 Java 虚拟机栈内存大小：

```java
java -Xss512M HackTheJava
```

该区域可能抛出以下异常：

- **当线程请求的栈深度超过最大值，会抛出 StackOverflowError 异常；**

举例：斐波那契数列

- **栈进行动态扩展时如果无法申请到足够内存，会抛出 OutOfMemoryError 异常。**

![1555636454852](.\picture\1188.png)



虚拟机栈是有一定的容量的，是由多个栈帧合起来的，每调用一个方法，jvm就会在内存中分配对应的一块空间，这块空间就是一个栈帧，当方法调用结束后，对应的栈帧就会被自动释放掉，这就是通常所说的栈的内存不需要通过GC去回收，而会自动释放的原因



##### 本地方法栈

本地方法栈与 Java 虚拟机栈类似，它们之间的区别只不过是本地方法栈为本地方法服务。

本地方法一般是用其它语言（C、C++ 或汇编语言等）编写的，并且被编译为基于本机硬件和操作系统的程序，对待这些方法需要特别处理。

<div align="center"> <img src="https://gitee.com/CyC2018/CS-Notes/raw/master/docs/pics/1_2001550547261811.png"/> </div><br>

##### 堆

所有对象都在这里分配内存，是垃圾收集的主要区域（"GC 堆"）。

现代的垃圾收集器基本都是采用分代收集算法，其主要的思想是针对不同类型的对象采取不同的垃圾回收算法。可以将堆分成两块：

- 新生代（Young Generation）
- 老年代（Old Generation）

堆不需要连续内存，并且可以动态增加其内存，增加失败会抛出 OutOfMemoryError 异常。

可以通过 -Xms 和 -Xmx 这两个虚拟机参数来指定一个程序的堆内存大小，第一个参数设置初始值，第二个参数设置最大值。

```java
java -Xms1M -Xmx2M HackTheJava
```

##### 方法区

用于存放已被加载的类信息、常量、静态变量、即时编译器编译后的代码等数据。

和堆一样不需要连续的内存，并且可以动态扩展，动态扩展失败一样会抛出 OutOfMemoryError 异常。

对这块区域进行垃圾回收的主要目标是对常量池的回收和对类的卸载，但是一般比较难实现。

HotSpot 虚拟机把它当成永久代来进行垃圾回收。但很难确定永久代的大小，因为它受到很多因素影响，并且每次 Full GC 之后永久代的大小都会改变，所以经常会抛出 OutOfMemoryError 异常。为了更容易管理方法区，从 JDK 1.8 开始，移除永久代，并把方法区移至元空间，它位于本地内存中，而不是虚拟机内存中。

##### 运行时常量池

运行时常量池是方法区的一部分。

Class 文件中的常量池（编译器生成的字面量和符号引用）会在类加载后被放入这个区域。

除了在编译期生成的常量，还允许动态生成，例如 String 类的 intern()。

##### 直接内存

在 JDK 1.4 中新引入了 NIO 类，它可以使用 Native 函数库直接分配堆外内存，然后通过 Java 堆里的 DirectByteBuffer 对象作为这块内存的引用进行操作。这样能在一些场景中显著提高性能，因为避免了在堆内存和堆外内存来回拷贝数据。



#### 面试考题

##### JVM三大性能调优参数-Xms -Xmx -Xss的含义

- **-Xss**：规定了每个线程虚拟机栈（堆栈）的大小
- **-Xms**：堆的初始值
- **-Xmx**：堆能达到的最大值



##### Java内存模型中堆和栈的区别—内存分配策略

- **静态存储**：编译时确定每个数据目标在运行时的存储空间需求，因此在编译时就可以给他们分配固定的内存空间，要求不允许有可变型数据结构，嵌套，递归
- **栈式存储**：数据区需求在编译时未知，在运行中进入一个程序模块的时候必须知道该程序模块所需要的数据区大小才能分配其内存
- **堆式存储**：适用于编译时或运行时模块入口都无法确定存储要求的数据结构的内存分配（例如可变长度串和对象实例），动态分配



##### Java内存模型中堆和栈的区别—联系

创建好的数组和对象实例都会被保存在堆内存中，想要引用堆中的某个对象或者数组，可以在栈中定义一个特殊的变量，让栈中的这个变量的取值等于数组和对象在堆内存中的首地址，栈中的这个变量就成了数组和对象的引用变量，以后就可以在程序中用栈中的引用变量来访问堆中的对象，引用变量就相当于为数组或者对象起的一个名称，引用变量是普通的变量，编译时在栈中分配，引用变量在程序运行至其作用域之外就会被释放掉，而数组和对象在堆中分配，即使程序运行到使用new去产生数组和对象的语句所在的代码块之外，数组和对象所占据的内存不会被释放掉，他们在没有引用变量指向的时候会变成垃圾，等待后面的一个不确定的时间被垃圾回收器释放掉。

![1555639101168](.\picture\1189.png)



![1555639218977](.\picture\1190.png)



栈空间因为只涉及到入栈和出栈指令，所以更加接近计算机底层，因此效率比较高，栈空间相对于堆空间的弱点是灵活性不够，堆胜在动态分配，它在计算机底层的实现可能是一个双向链表的结构，操作的时候比栈空间复杂，灵活性高，效率低



##### 不同JDK版本之间的intern()方法的区别JDK6和JDK6+

![1555652528995](.\picture\1191.png)

**总结**：一个可以在常量池中添加对象，一个在常量池中增加添加引用



==jdk1.6版本后的hotspot将字符串常量池从永久代中移出了，接受垃圾回收器的回收==



```java
/**
 * JDK6打印出false和false
 * JDK6+打印出false和true
 */
public class InternDifference {
    public static void main(String[] args) {
        String s = new String("a");
        s.intern();
        String s2 = "a";
        /**
         * 这里比较的是两个字符串的地址
         */
        System.out.println(s == s2);

        String s3 = new String("a") + new String("a");
        s3.intern();
        String s4 = "aa";
        /**
         * 这里比较的是两个字符串的地址
         */
        System.out.println(s3 == s4);
    }
}
```



总结：在引号中声明的字符串都可以在字符串常量池中创建出来，而new出来的字符串对象是在堆中创建出来的，所以**==new String("a")经历了常量池的创建和堆中的对象的创建==**



JDK6：

![1555654636551](.\picture\1192.png)



String s = new String("a")中在字符串常量池创建了”a“，然后在堆中创建了s对象

s.intern()试图在常量池中创建”a“的==副本==（对象），然后发现创建不进去





 String s3 = new String("a") + new String("a");
 s3.intern();

这两句在堆中创建了一个”aa“对象，并在字符串常量池中创建了”aa“





JDK7及以上：

![1555654772144](.\picture\1193.png)



String s = new String("a")中在字符串常量池创建了”a“，然后在堆中创建了s对象

s.intern()发现字符串常量池中已经有”a“了，==所以不能传入引用了==



 String s3 = new String("a") + new String("a");
 s3.intern();

这两句在堆中创建了一个”aa“对象，==并把这个对象的引用传到字符串常量池中==

